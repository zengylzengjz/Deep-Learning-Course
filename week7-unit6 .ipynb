{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM   ZN   INDUS   CHAS    NOX     RM    AGE     DIS  RAD  TAX  \\\n",
      "0     0.00632  18.0    2.31     0  0.538  6.575   65.2  4.0900    1  296   \n",
      "1     0.02731   0.0    7.07     0  0.469  6.421   78.9  4.9671    2  242   \n",
      "2     0.02729   0.0    7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
      "3     0.03237   0.0    2.18     0  0.458  6.998   45.8  6.0622    3  222   \n",
      "4     0.06905   0.0    2.18     0  0.458  7.147   54.2  6.0622    3  222   \n",
      "5     0.02985   0.0    2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
      "6     0.08829  12.5    7.87     0  0.524  6.012   66.6  5.5605    5  311   \n",
      "7     0.14455  12.5    7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
      "8     0.21124  12.5    7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
      "9     0.17004  12.5    7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
      "10    0.22489  12.5    7.87     0  0.524  6.377   94.3  6.3467    5  311   \n",
      "11    0.11747  12.5    7.87     0  0.524  6.009   82.9  6.2267    5  311   \n",
      "12    0.09378  12.5    7.87     0  0.524  5.889   39.0  5.4509    5  311   \n",
      "13    0.62976   0.0    8.14     0  0.538  5.949   61.8  4.7075    4  307   \n",
      "14    0.63796   0.0    8.14     0  0.538  6.096   84.5  4.4619    4  307   \n",
      "15    0.62739   0.0    8.14     0  0.538  5.834   56.5  4.4986    4  307   \n",
      "16    1.05393   0.0    8.14     0  0.538  5.935   29.3  4.4986    4  307   \n",
      "17    0.78420   0.0    8.14     0  0.538  5.990   81.7  4.2579    4  307   \n",
      "18    0.80271   0.0    8.14     0  0.538  5.456   36.6  3.7965    4  307   \n",
      "19    0.72580   0.0    8.14     0  0.538  5.727   69.5  3.7965    4  307   \n",
      "20    1.25179   0.0    8.14     0  0.538  5.570   98.1  3.7979    4  307   \n",
      "21    0.85204   0.0    8.14     0  0.538  5.965   89.2  4.0123    4  307   \n",
      "22    1.23247   0.0    8.14     0  0.538  6.142   91.7  3.9769    4  307   \n",
      "23    0.98843   0.0    8.14     0  0.538  5.813  100.0  4.0952    4  307   \n",
      "24    0.75026   0.0    8.14     0  0.538  5.924   94.1  4.3996    4  307   \n",
      "25    0.84054   0.0    8.14     0  0.538  5.599   85.7  4.4546    4  307   \n",
      "26    0.67191   0.0    8.14     0  0.538  5.813   90.3  4.6820    4  307   \n",
      "27    0.95577   0.0    8.14     0  0.538  6.047   88.8  4.4534    4  307   \n",
      "28    0.77299   0.0    8.14     0  0.538  6.495   94.4  4.4547    4  307   \n",
      "29    1.00245   0.0    8.14     0  0.538  6.674   87.3  4.2390    4  307   \n",
      "..        ...   ...     ...   ...    ...    ...    ...     ...  ...  ...   \n",
      "476   4.87141   0.0   18.10     0  0.614  6.484   93.6  2.3053   24  666   \n",
      "477  15.02340   0.0   18.10     0  0.614  5.304   97.3  2.1007   24  666   \n",
      "478  10.23300   0.0   18.10     0  0.614  6.185   96.7  2.1705   24  666   \n",
      "479  14.33370   0.0   18.10     0  0.614  6.229   88.0  1.9512   24  666   \n",
      "480   5.82401   0.0   18.10     0  0.532  6.242   64.7  3.4242   24  666   \n",
      "481   5.70818   0.0   18.10     0  0.532  6.750   74.9  3.3317   24  666   \n",
      "482   5.73116   0.0   18.10     0  0.532  7.061   77.0  3.4106   24  666   \n",
      "483   2.81838   0.0   18.10     0  0.532  5.762   40.3  4.0983   24  666   \n",
      "484   2.37857   0.0   18.10     0  0.583  5.871   41.9  3.7240   24  666   \n",
      "485   3.67367   0.0   18.10     0  0.583  6.312   51.9  3.9917   24  666   \n",
      "486   5.69175   0.0   18.10     0  0.583  6.114   79.8  3.5459   24  666   \n",
      "487   4.83567   0.0   18.10     0  0.583  5.905   53.2  3.1523   24  666   \n",
      "488   0.15086   0.0   27.74     0  0.609  5.454   92.7  1.8209    4  711   \n",
      "489   0.18337   0.0   27.74     0  0.609  5.414   98.3  1.7554    4  711   \n",
      "490   0.20746   0.0   27.74     0  0.609  5.093   98.0  1.8226    4  711   \n",
      "491   0.10574   0.0   27.74     0  0.609  5.983   98.8  1.8681    4  711   \n",
      "492   0.11132   0.0   27.74     0  0.609  5.983   83.5  2.1099    4  711   \n",
      "493   0.17331   0.0    9.69     0  0.585  5.707   54.0  2.3817    6  391   \n",
      "494   0.27957   0.0    9.69     0  0.585  5.926   42.6  2.3817    6  391   \n",
      "495   0.17899   0.0    9.69     0  0.585  5.670   28.8  2.7986    6  391   \n",
      "496   0.28960   0.0    9.69     0  0.585  5.390   72.9  2.7986    6  391   \n",
      "497   0.26838   0.0    9.69     0  0.585  5.794   70.6  2.8927    6  391   \n",
      "498   0.23912   0.0    9.69     0  0.585  6.019   65.3  2.4091    6  391   \n",
      "499   0.17783   0.0    9.69     0  0.585  5.569   73.5  2.3999    6  391   \n",
      "500   0.22438   0.0    9.69     0  0.585  6.027   79.7  2.4982    6  391   \n",
      "501   0.06263   0.0   11.93     0  0.573  6.593   69.1  2.4786    1  273   \n",
      "502   0.04527   0.0   11.93     0  0.573  6.120   76.7  2.2875    1  273   \n",
      "503   0.06076   0.0   11.93     0  0.573  6.976   91.0  2.1675    1  273   \n",
      "504   0.10959   0.0   11.93     0  0.573  6.794   89.3  2.3889    1  273   \n",
      "505   0.04741   0.0   11.93     0  0.573  6.030   80.8  2.5050    1  273   \n",
      "\n",
      "     PTRATIO  LSTAT  MEDV  \n",
      "0       15.3   4.98  24.0  \n",
      "1       17.8   9.14  21.6  \n",
      "2       17.8   4.03  34.7  \n",
      "3       18.7   2.94  33.4  \n",
      "4       18.7   5.33  36.2  \n",
      "5       18.7   5.21  28.7  \n",
      "6       15.2  12.43  22.9  \n",
      "7       15.2  19.15  27.1  \n",
      "8       15.2  29.93  16.5  \n",
      "9       15.2  17.10  18.9  \n",
      "10      15.2  20.45  15.0  \n",
      "11      15.2  13.27  18.9  \n",
      "12      15.2  15.71  21.7  \n",
      "13      21.0   8.26  20.4  \n",
      "14      21.0  10.26  18.2  \n",
      "15      21.0   8.47  19.9  \n",
      "16      21.0   6.58  23.1  \n",
      "17      21.0  14.67  17.5  \n",
      "18      21.0  11.69  20.2  \n",
      "19      21.0  11.28  18.2  \n",
      "20      21.0  21.02  13.6  \n",
      "21      21.0  13.83  19.6  \n",
      "22      21.0  18.72  15.2  \n",
      "23      21.0  19.88  14.5  \n",
      "24      21.0  16.30  15.6  \n",
      "25      21.0  16.51  13.9  \n",
      "26      21.0  14.81  16.6  \n",
      "27      21.0  17.28  14.8  \n",
      "28      21.0  12.80  18.4  \n",
      "29      21.0  11.98  21.0  \n",
      "..       ...    ...   ...  \n",
      "476     20.2  18.68  16.7  \n",
      "477     20.2  24.91  12.0  \n",
      "478     20.2  18.03  14.6  \n",
      "479     20.2  13.11  21.4  \n",
      "480     20.2  10.74  23.0  \n",
      "481     20.2   7.74  23.7  \n",
      "482     20.2   7.01  25.0  \n",
      "483     20.2  10.42  21.8  \n",
      "484     20.2  13.34  20.6  \n",
      "485     20.2  10.58  21.2  \n",
      "486     20.2  14.98  19.1  \n",
      "487     20.2  11.45  20.6  \n",
      "488     20.1  18.06  15.2  \n",
      "489     20.1  23.97   7.0  \n",
      "490     20.1  29.68   8.1  \n",
      "491     20.1  18.07  13.6  \n",
      "492     20.1  13.35  20.1  \n",
      "493     19.2  12.01  21.8  \n",
      "494     19.2  13.59  24.5  \n",
      "495     19.2  17.60  23.1  \n",
      "496     19.2  21.14  19.7  \n",
      "497     19.2  14.10  18.3  \n",
      "498     19.2  12.92  21.2  \n",
      "499     19.2  15.10  17.5  \n",
      "500     19.2  14.33  16.8  \n",
      "501     21.0   9.67  22.4  \n",
      "502     21.0   9.08  20.6  \n",
      "503     21.0   5.64  23.9  \n",
      "504     21.0   6.48  22.0  \n",
      "505     21.0   7.88  11.9  \n",
      "\n",
      "[506 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"boston.csv\",header=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM   ZN   INDUS   CHAS    NOX     RM    AGE     DIS  RAD  TAX  \\\n",
      "0     0.00632  18.0    2.31     0  0.538  6.575   65.2  4.0900    1  296   \n",
      "1     0.02731   0.0    7.07     0  0.469  6.421   78.9  4.9671    2  242   \n",
      "2     0.02729   0.0    7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
      "3     0.03237   0.0    2.18     0  0.458  6.998   45.8  6.0622    3  222   \n",
      "4     0.06905   0.0    2.18     0  0.458  7.147   54.2  6.0622    3  222   \n",
      "5     0.02985   0.0    2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
      "6     0.08829  12.5    7.87     0  0.524  6.012   66.6  5.5605    5  311   \n",
      "7     0.14455  12.5    7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
      "8     0.21124  12.5    7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
      "9     0.17004  12.5    7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
      "10    0.22489  12.5    7.87     0  0.524  6.377   94.3  6.3467    5  311   \n",
      "11    0.11747  12.5    7.87     0  0.524  6.009   82.9  6.2267    5  311   \n",
      "12    0.09378  12.5    7.87     0  0.524  5.889   39.0  5.4509    5  311   \n",
      "13    0.62976   0.0    8.14     0  0.538  5.949   61.8  4.7075    4  307   \n",
      "14    0.63796   0.0    8.14     0  0.538  6.096   84.5  4.4619    4  307   \n",
      "15    0.62739   0.0    8.14     0  0.538  5.834   56.5  4.4986    4  307   \n",
      "16    1.05393   0.0    8.14     0  0.538  5.935   29.3  4.4986    4  307   \n",
      "17    0.78420   0.0    8.14     0  0.538  5.990   81.7  4.2579    4  307   \n",
      "18    0.80271   0.0    8.14     0  0.538  5.456   36.6  3.7965    4  307   \n",
      "19    0.72580   0.0    8.14     0  0.538  5.727   69.5  3.7965    4  307   \n",
      "20    1.25179   0.0    8.14     0  0.538  5.570   98.1  3.7979    4  307   \n",
      "21    0.85204   0.0    8.14     0  0.538  5.965   89.2  4.0123    4  307   \n",
      "22    1.23247   0.0    8.14     0  0.538  6.142   91.7  3.9769    4  307   \n",
      "23    0.98843   0.0    8.14     0  0.538  5.813  100.0  4.0952    4  307   \n",
      "24    0.75026   0.0    8.14     0  0.538  5.924   94.1  4.3996    4  307   \n",
      "25    0.84054   0.0    8.14     0  0.538  5.599   85.7  4.4546    4  307   \n",
      "26    0.67191   0.0    8.14     0  0.538  5.813   90.3  4.6820    4  307   \n",
      "27    0.95577   0.0    8.14     0  0.538  6.047   88.8  4.4534    4  307   \n",
      "28    0.77299   0.0    8.14     0  0.538  6.495   94.4  4.4547    4  307   \n",
      "29    1.00245   0.0    8.14     0  0.538  6.674   87.3  4.2390    4  307   \n",
      "..        ...   ...     ...   ...    ...    ...    ...     ...  ...  ...   \n",
      "476   4.87141   0.0   18.10     0  0.614  6.484   93.6  2.3053   24  666   \n",
      "477  15.02340   0.0   18.10     0  0.614  5.304   97.3  2.1007   24  666   \n",
      "478  10.23300   0.0   18.10     0  0.614  6.185   96.7  2.1705   24  666   \n",
      "479  14.33370   0.0   18.10     0  0.614  6.229   88.0  1.9512   24  666   \n",
      "480   5.82401   0.0   18.10     0  0.532  6.242   64.7  3.4242   24  666   \n",
      "481   5.70818   0.0   18.10     0  0.532  6.750   74.9  3.3317   24  666   \n",
      "482   5.73116   0.0   18.10     0  0.532  7.061   77.0  3.4106   24  666   \n",
      "483   2.81838   0.0   18.10     0  0.532  5.762   40.3  4.0983   24  666   \n",
      "484   2.37857   0.0   18.10     0  0.583  5.871   41.9  3.7240   24  666   \n",
      "485   3.67367   0.0   18.10     0  0.583  6.312   51.9  3.9917   24  666   \n",
      "486   5.69175   0.0   18.10     0  0.583  6.114   79.8  3.5459   24  666   \n",
      "487   4.83567   0.0   18.10     0  0.583  5.905   53.2  3.1523   24  666   \n",
      "488   0.15086   0.0   27.74     0  0.609  5.454   92.7  1.8209    4  711   \n",
      "489   0.18337   0.0   27.74     0  0.609  5.414   98.3  1.7554    4  711   \n",
      "490   0.20746   0.0   27.74     0  0.609  5.093   98.0  1.8226    4  711   \n",
      "491   0.10574   0.0   27.74     0  0.609  5.983   98.8  1.8681    4  711   \n",
      "492   0.11132   0.0   27.74     0  0.609  5.983   83.5  2.1099    4  711   \n",
      "493   0.17331   0.0    9.69     0  0.585  5.707   54.0  2.3817    6  391   \n",
      "494   0.27957   0.0    9.69     0  0.585  5.926   42.6  2.3817    6  391   \n",
      "495   0.17899   0.0    9.69     0  0.585  5.670   28.8  2.7986    6  391   \n",
      "496   0.28960   0.0    9.69     0  0.585  5.390   72.9  2.7986    6  391   \n",
      "497   0.26838   0.0    9.69     0  0.585  5.794   70.6  2.8927    6  391   \n",
      "498   0.23912   0.0    9.69     0  0.585  6.019   65.3  2.4091    6  391   \n",
      "499   0.17783   0.0    9.69     0  0.585  5.569   73.5  2.3999    6  391   \n",
      "500   0.22438   0.0    9.69     0  0.585  6.027   79.7  2.4982    6  391   \n",
      "501   0.06263   0.0   11.93     0  0.573  6.593   69.1  2.4786    1  273   \n",
      "502   0.04527   0.0   11.93     0  0.573  6.120   76.7  2.2875    1  273   \n",
      "503   0.06076   0.0   11.93     0  0.573  6.976   91.0  2.1675    1  273   \n",
      "504   0.10959   0.0   11.93     0  0.573  6.794   89.3  2.3889    1  273   \n",
      "505   0.04741   0.0   11.93     0  0.573  6.030   80.8  2.5050    1  273   \n",
      "\n",
      "     PTRATIO  LSTAT  MEDV  \n",
      "0       15.3   4.98  24.0  \n",
      "1       17.8   9.14  21.6  \n",
      "2       17.8   4.03  34.7  \n",
      "3       18.7   2.94  33.4  \n",
      "4       18.7   5.33  36.2  \n",
      "5       18.7   5.21  28.7  \n",
      "6       15.2  12.43  22.9  \n",
      "7       15.2  19.15  27.1  \n",
      "8       15.2  29.93  16.5  \n",
      "9       15.2  17.10  18.9  \n",
      "10      15.2  20.45  15.0  \n",
      "11      15.2  13.27  18.9  \n",
      "12      15.2  15.71  21.7  \n",
      "13      21.0   8.26  20.4  \n",
      "14      21.0  10.26  18.2  \n",
      "15      21.0   8.47  19.9  \n",
      "16      21.0   6.58  23.1  \n",
      "17      21.0  14.67  17.5  \n",
      "18      21.0  11.69  20.2  \n",
      "19      21.0  11.28  18.2  \n",
      "20      21.0  21.02  13.6  \n",
      "21      21.0  13.83  19.6  \n",
      "22      21.0  18.72  15.2  \n",
      "23      21.0  19.88  14.5  \n",
      "24      21.0  16.30  15.6  \n",
      "25      21.0  16.51  13.9  \n",
      "26      21.0  14.81  16.6  \n",
      "27      21.0  17.28  14.8  \n",
      "28      21.0  12.80  18.4  \n",
      "29      21.0  11.98  21.0  \n",
      "..       ...    ...   ...  \n",
      "476     20.2  18.68  16.7  \n",
      "477     20.2  24.91  12.0  \n",
      "478     20.2  18.03  14.6  \n",
      "479     20.2  13.11  21.4  \n",
      "480     20.2  10.74  23.0  \n",
      "481     20.2   7.74  23.7  \n",
      "482     20.2   7.01  25.0  \n",
      "483     20.2  10.42  21.8  \n",
      "484     20.2  13.34  20.6  \n",
      "485     20.2  10.58  21.2  \n",
      "486     20.2  14.98  19.1  \n",
      "487     20.2  11.45  20.6  \n",
      "488     20.1  18.06  15.2  \n",
      "489     20.1  23.97   7.0  \n",
      "490     20.1  29.68   8.1  \n",
      "491     20.1  18.07  13.6  \n",
      "492     20.1  13.35  20.1  \n",
      "493     19.2  12.01  21.8  \n",
      "494     19.2  13.59  24.5  \n",
      "495     19.2  17.60  23.1  \n",
      "496     19.2  21.14  19.7  \n",
      "497     19.2  14.10  18.3  \n",
      "498     19.2  12.92  21.2  \n",
      "499     19.2  15.10  17.5  \n",
      "500     19.2  14.33  16.8  \n",
      "501     21.0   9.67  22.4  \n",
      "502     21.0   9.08  20.6  \n",
      "503     21.0   5.64  23.9  \n",
      "504     21.0   6.48  22.0  \n",
      "505     21.0   7.88  11.9  \n",
      "\n",
      "[506 rows x 13 columns]\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 4.9800e+00 2.4000e+01]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 9.1400e+00 2.1600e+01]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 4.0300e+00 3.4700e+01]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 5.6400e+00 2.3900e+01]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 6.4800e+00 2.2000e+01]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 7.8800e+00 1.1900e+01]]\n",
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 2.9600e+02 1.5300e+01 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 2.4200e+02 1.7800e+01 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 2.4200e+02 1.7800e+01 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.7300e+02 2.1000e+01 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.7300e+02 2.1000e+01 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.7300e+02 2.1000e+01 7.8800e+00]] \n",
      " shape= (506, 12)\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9] \n",
      " shape= (506,)\n"
     ]
    }
   ],
   "source": [
    "df = df\n",
    "print(df)\n",
    "df =np.array(df)\n",
    "print(df)\n",
    "x_data = df[:,:12]\n",
    "y_data = df[:,12]\n",
    "print(x_data,'\\n shape=',x_data.shape)\n",
    "print(y_data,'\\n shape=',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 300\n",
    "valid_num = 100\n",
    "test_num = len(x_data)- train_num -valid_num\n",
    "\n",
    "x_train = x_data[:train_num]\n",
    "y_train = y_data[:train_num]\n",
    "\n",
    "x_valid = x_data[train_num:train_num+valid_num]\n",
    "y_valid = y_data[train_num:train_num+valid_num]\n",
    "\n",
    "x_test = x_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "y_test = y_data[train_num+valid_num:train_num+valid_num+test_num]\n",
    "\n",
    "x_train = tf.cast(scale(x_train), dtype=tf.float32)\n",
    "x_valid = tf.cast(scale(x_valid), dtype=tf.float32)\n",
    "x_test = tf.cast(scale(x_test), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[ 0.9763091 ],\n",
      "       [-0.3685155 ],\n",
      "       [ 0.49096242],\n",
      "       [ 0.5959448 ],\n",
      "       [-0.06455412],\n",
      "       [-0.6748196 ],\n",
      "       [ 0.08178204],\n",
      "       [-1.4440577 ],\n",
      "       [-0.69310975],\n",
      "       [-1.8991889 ],\n",
      "       [-1.3837553 ],\n",
      "       [ 1.5373732 ]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "def model(x, w, b):\n",
    "    return tf.matmul(x,w)+ b\n",
    "\n",
    "W = tf.Variable(tf.random.normal([12,1],mean=0.0, stddev = 1.0, dtype=tf.float32))\n",
    "B = tf.Variable(tf.zeros(1), dtype = tf.float32)\n",
    "\n",
    "print(W)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 500\n",
    "learning_rate = 0.0001\n",
    "batch_size = 10\n",
    "def loss(x,y,w,b):\n",
    "    err = model(x,w,b)-y\n",
    "    squared_err = tf.square(err)\n",
    "    return tf.reduce_mean(squared_err)\n",
    "def grad(x,y,w,b):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x,y,w,b)\n",
    "    return tape.gradient(loss_, [w,b])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1 ,train_loss=735.8864,valid_loss=519.0682\n",
      "epoch=  2 ,train_loss=727.3947,valid_loss=512.4758\n",
      "epoch=  3 ,train_loss=719.0653,valid_loss=506.0312\n",
      "epoch=  4 ,train_loss=710.8928,valid_loss=499.7284\n",
      "epoch=  5 ,train_loss=702.8717,valid_loss=493.5618\n",
      "epoch=  6 ,train_loss=694.9971,valid_loss=487.5259\n",
      "epoch=  7 ,train_loss=687.2638,valid_loss=481.6158\n",
      "epoch=  8 ,train_loss=679.6675,valid_loss=475.8263\n",
      "epoch=  9 ,train_loss=672.2037,valid_loss=470.1533\n",
      "epoch= 10 ,train_loss=664.8683,valid_loss=464.5920\n",
      "epoch= 11 ,train_loss=657.6573,valid_loss=459.1386\n",
      "epoch= 12 ,train_loss=650.5671,valid_loss=453.7892\n",
      "epoch= 13 ,train_loss=643.5938,valid_loss=448.5400\n",
      "epoch= 14 ,train_loss=636.7341,valid_loss=443.3877\n",
      "epoch= 15 ,train_loss=629.9849,valid_loss=438.3289\n",
      "epoch= 16 ,train_loss=623.3428,valid_loss=433.3605\n",
      "epoch= 17 ,train_loss=616.8050,valid_loss=428.4797\n",
      "epoch= 18 ,train_loss=610.3687,valid_loss=423.6836\n",
      "epoch= 19 ,train_loss=604.0311,valid_loss=418.9695\n",
      "epoch= 20 ,train_loss=597.7897,valid_loss=414.3350\n",
      "epoch= 21 ,train_loss=591.6420,valid_loss=409.7775\n",
      "epoch= 22 ,train_loss=585.5856,valid_loss=405.2951\n",
      "epoch= 23 ,train_loss=579.6182,valid_loss=400.8853\n",
      "epoch= 24 ,train_loss=573.7377,valid_loss=396.5462\n",
      "epoch= 25 ,train_loss=567.9421,valid_loss=392.2758\n",
      "epoch= 26 ,train_loss=562.2293,valid_loss=388.0725\n",
      "epoch= 27 ,train_loss=556.5975,valid_loss=383.9342\n",
      "epoch= 28 ,train_loss=551.0448,valid_loss=379.8596\n",
      "epoch= 29 ,train_loss=545.5694,valid_loss=375.8466\n",
      "epoch= 30 ,train_loss=540.1697,valid_loss=371.8940\n",
      "epoch= 31 ,train_loss=534.8441,valid_loss=368.0003\n",
      "epoch= 32 ,train_loss=529.5910,valid_loss=364.1644\n",
      "epoch= 33 ,train_loss=524.4090,valid_loss=360.3846\n",
      "epoch= 34 ,train_loss=519.2964,valid_loss=356.6597\n",
      "epoch= 35 ,train_loss=514.2522,valid_loss=352.9886\n",
      "epoch= 36 ,train_loss=509.2749,valid_loss=349.3702\n",
      "epoch= 37 ,train_loss=504.3632,valid_loss=345.8032\n",
      "epoch= 38 ,train_loss=499.5157,valid_loss=342.2867\n",
      "epoch= 39 ,train_loss=494.7316,valid_loss=338.8198\n",
      "epoch= 40 ,train_loss=490.0094,valid_loss=335.4013\n",
      "epoch= 41 ,train_loss=485.3483,valid_loss=332.0304\n",
      "epoch= 42 ,train_loss=480.7468,valid_loss=328.7061\n",
      "epoch= 43 ,train_loss=476.2042,valid_loss=325.4276\n",
      "epoch= 44 ,train_loss=471.7194,valid_loss=322.1942\n",
      "epoch= 45 ,train_loss=467.2915,valid_loss=319.0050\n",
      "epoch= 46 ,train_loss=462.9193,valid_loss=315.8592\n",
      "epoch= 47 ,train_loss=458.6022,valid_loss=312.7562\n",
      "epoch= 48 ,train_loss=454.3391,valid_loss=309.6950\n",
      "epoch= 49 ,train_loss=450.1292,valid_loss=306.6752\n",
      "epoch= 50 ,train_loss=445.9716,valid_loss=303.6960\n",
      "epoch= 51 ,train_loss=441.8656,valid_loss=300.7568\n",
      "epoch= 52 ,train_loss=437.8104,valid_loss=297.8571\n",
      "epoch= 53 ,train_loss=433.8051,valid_loss=294.9960\n",
      "epoch= 54 ,train_loss=429.8491,valid_loss=292.1731\n",
      "epoch= 55 ,train_loss=425.9416,valid_loss=289.3880\n",
      "epoch= 56 ,train_loss=422.0819,valid_loss=286.6399\n",
      "epoch= 57 ,train_loss=418.2693,valid_loss=283.9283\n",
      "epoch= 58 ,train_loss=414.5031,valid_loss=281.2528\n",
      "epoch= 59 ,train_loss=410.7826,valid_loss=278.6127\n",
      "epoch= 60 ,train_loss=407.1073,valid_loss=276.0077\n",
      "epoch= 61 ,train_loss=403.4764,valid_loss=273.4373\n",
      "epoch= 62 ,train_loss=399.8894,valid_loss=270.9009\n",
      "epoch= 63 ,train_loss=396.3459,valid_loss=268.3983\n",
      "epoch= 64 ,train_loss=392.8449,valid_loss=265.9289\n",
      "epoch= 65 ,train_loss=389.3860,valid_loss=263.4921\n",
      "epoch= 66 ,train_loss=385.9686,valid_loss=261.0876\n",
      "epoch= 67 ,train_loss=382.5922,valid_loss=258.7151\n",
      "epoch= 68 ,train_loss=379.2563,valid_loss=256.3741\n",
      "epoch= 69 ,train_loss=375.9603,valid_loss=254.0641\n",
      "epoch= 70 ,train_loss=372.7037,valid_loss=251.7849\n",
      "epoch= 71 ,train_loss=369.4859,valid_loss=249.5361\n",
      "epoch= 72 ,train_loss=366.3067,valid_loss=247.3172\n",
      "epoch= 73 ,train_loss=363.1653,valid_loss=245.1280\n",
      "epoch= 74 ,train_loss=360.0613,valid_loss=242.9678\n",
      "epoch= 75 ,train_loss=356.9942,valid_loss=240.8366\n",
      "epoch= 76 ,train_loss=353.9637,valid_loss=238.7340\n",
      "epoch= 77 ,train_loss=350.9691,valid_loss=236.6595\n",
      "epoch= 78 ,train_loss=348.0103,valid_loss=234.6129\n",
      "epoch= 79 ,train_loss=345.0864,valid_loss=232.5937\n",
      "epoch= 80 ,train_loss=342.1972,valid_loss=230.6018\n",
      "epoch= 81 ,train_loss=339.3425,valid_loss=228.6368\n",
      "epoch= 82 ,train_loss=336.5215,valid_loss=226.6983\n",
      "epoch= 83 ,train_loss=333.7339,valid_loss=224.7859\n",
      "epoch= 84 ,train_loss=330.9794,valid_loss=222.8995\n",
      "epoch= 85 ,train_loss=328.2574,valid_loss=221.0387\n",
      "epoch= 86 ,train_loss=325.5676,valid_loss=219.2032\n",
      "epoch= 87 ,train_loss=322.9097,valid_loss=217.3927\n",
      "epoch= 88 ,train_loss=320.2832,valid_loss=215.6068\n",
      "epoch= 89 ,train_loss=317.6877,valid_loss=213.8454\n",
      "epoch= 90 ,train_loss=315.1230,valid_loss=212.1082\n",
      "epoch= 91 ,train_loss=312.5887,valid_loss=210.3950\n",
      "epoch= 92 ,train_loss=310.0844,valid_loss=208.7052\n",
      "epoch= 93 ,train_loss=307.6096,valid_loss=207.0387\n",
      "epoch= 94 ,train_loss=305.1640,valid_loss=205.3953\n",
      "epoch= 95 ,train_loss=302.7474,valid_loss=203.7747\n",
      "epoch= 96 ,train_loss=300.3594,valid_loss=202.1765\n",
      "epoch= 97 ,train_loss=297.9995,valid_loss=200.6006\n",
      "epoch= 98 ,train_loss=295.6676,valid_loss=199.0467\n",
      "epoch= 99 ,train_loss=293.3632,valid_loss=197.5143\n",
      "epoch=100 ,train_loss=291.0860,valid_loss=196.0037\n",
      "epoch=101 ,train_loss=288.8357,valid_loss=194.5141\n",
      "epoch=102 ,train_loss=286.6120,valid_loss=193.0455\n",
      "epoch=103 ,train_loss=284.4145,valid_loss=191.5975\n",
      "epoch=104 ,train_loss=282.2430,valid_loss=190.1701\n",
      "epoch=105 ,train_loss=280.0973,valid_loss=188.7630\n",
      "epoch=106 ,train_loss=277.9768,valid_loss=187.3757\n",
      "epoch=107 ,train_loss=275.8814,valid_loss=186.0083\n",
      "epoch=108 ,train_loss=273.8109,valid_loss=184.6604\n",
      "epoch=109 ,train_loss=271.7647,valid_loss=183.3318\n",
      "epoch=110 ,train_loss=269.7429,valid_loss=182.0223\n",
      "epoch=111 ,train_loss=267.7450,valid_loss=180.7316\n",
      "epoch=112 ,train_loss=265.7705,valid_loss=179.4595\n",
      "epoch=113 ,train_loss=263.8196,valid_loss=178.2059\n",
      "epoch=114 ,train_loss=261.8917,valid_loss=176.9704\n",
      "epoch=115 ,train_loss=259.9865,valid_loss=175.7529\n",
      "epoch=116 ,train_loss=258.1039,valid_loss=174.5531\n",
      "epoch=117 ,train_loss=256.2437,valid_loss=173.3709\n",
      "epoch=118 ,train_loss=254.4053,valid_loss=172.2059\n",
      "epoch=119 ,train_loss=252.5888,valid_loss=171.0581\n",
      "epoch=120 ,train_loss=250.7938,valid_loss=169.9273\n",
      "epoch=121 ,train_loss=249.0200,valid_loss=168.8131\n",
      "epoch=122 ,train_loss=247.2673,valid_loss=167.7155\n",
      "epoch=123 ,train_loss=245.5353,valid_loss=166.6341\n",
      "epoch=124 ,train_loss=243.8238,valid_loss=165.5688\n",
      "epoch=125 ,train_loss=242.1327,valid_loss=164.5196\n",
      "epoch=126 ,train_loss=240.4616,valid_loss=163.4859\n",
      "epoch=127 ,train_loss=238.8102,valid_loss=162.4678\n",
      "epoch=128 ,train_loss=237.1784,valid_loss=161.4651\n",
      "epoch=129 ,train_loss=235.5660,valid_loss=160.4775\n",
      "epoch=130 ,train_loss=233.9727,valid_loss=159.5049\n",
      "epoch=131 ,train_loss=232.3983,valid_loss=158.5470\n",
      "epoch=132 ,train_loss=230.8427,valid_loss=157.6037\n",
      "epoch=133 ,train_loss=229.3054,valid_loss=156.6750\n",
      "epoch=134 ,train_loss=227.7864,valid_loss=155.7604\n",
      "epoch=135 ,train_loss=226.2854,valid_loss=154.8599\n",
      "epoch=136 ,train_loss=224.8023,valid_loss=153.9733\n",
      "epoch=137 ,train_loss=223.3368,valid_loss=153.1004\n",
      "epoch=138 ,train_loss=221.8887,valid_loss=152.2411\n",
      "epoch=139 ,train_loss=220.4577,valid_loss=151.3951\n",
      "epoch=140 ,train_loss=219.0438,valid_loss=150.5624\n",
      "epoch=141 ,train_loss=217.6466,valid_loss=149.7427\n",
      "epoch=142 ,train_loss=216.2661,valid_loss=148.9359\n",
      "epoch=143 ,train_loss=214.9020,valid_loss=148.1418\n",
      "epoch=144 ,train_loss=213.5541,valid_loss=147.3602\n",
      "epoch=145 ,train_loss=212.2222,valid_loss=146.5911\n",
      "epoch=146 ,train_loss=210.9061,valid_loss=145.8342\n",
      "epoch=147 ,train_loss=209.6057,valid_loss=145.0894\n",
      "epoch=148 ,train_loss=208.3208,valid_loss=144.3566\n",
      "epoch=149 ,train_loss=207.0511,valid_loss=143.6355\n",
      "epoch=150 ,train_loss=205.7965,valid_loss=142.9260\n",
      "epoch=151 ,train_loss=204.5569,valid_loss=142.2281\n",
      "epoch=152 ,train_loss=203.3320,valid_loss=141.5414\n",
      "epoch=153 ,train_loss=202.1217,valid_loss=140.8660\n",
      "epoch=154 ,train_loss=200.9258,valid_loss=140.2017\n",
      "epoch=155 ,train_loss=199.7441,valid_loss=139.5482\n",
      "epoch=156 ,train_loss=198.5765,valid_loss=138.9055\n",
      "epoch=157 ,train_loss=197.4228,valid_loss=138.2734\n",
      "epoch=158 ,train_loss=196.2829,valid_loss=137.6519\n",
      "epoch=159 ,train_loss=195.1566,valid_loss=137.0406\n",
      "epoch=160 ,train_loss=194.0436,valid_loss=136.4396\n",
      "epoch=161 ,train_loss=192.9440,valid_loss=135.8487\n",
      "epoch=162 ,train_loss=191.8573,valid_loss=135.2677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=163 ,train_loss=190.7837,valid_loss=134.6965\n",
      "epoch=164 ,train_loss=189.7229,valid_loss=134.1351\n",
      "epoch=165 ,train_loss=188.6747,valid_loss=133.5833\n",
      "epoch=166 ,train_loss=187.6390,valid_loss=133.0408\n",
      "epoch=167 ,train_loss=186.6158,valid_loss=132.5077\n",
      "epoch=168 ,train_loss=185.6047,valid_loss=131.9838\n",
      "epoch=169 ,train_loss=184.6057,valid_loss=131.4690\n",
      "epoch=170 ,train_loss=183.6185,valid_loss=130.9631\n",
      "epoch=171 ,train_loss=182.6431,valid_loss=130.4661\n",
      "epoch=172 ,train_loss=181.6795,valid_loss=129.9778\n",
      "epoch=173 ,train_loss=180.7272,valid_loss=129.4981\n",
      "epoch=174 ,train_loss=179.7864,valid_loss=129.0269\n",
      "epoch=175 ,train_loss=178.8568,valid_loss=128.5640\n",
      "epoch=176 ,train_loss=177.9383,valid_loss=128.1095\n",
      "epoch=177 ,train_loss=177.0307,valid_loss=127.6630\n",
      "epoch=178 ,train_loss=176.1340,valid_loss=127.2246\n",
      "epoch=179 ,train_loss=175.2480,valid_loss=126.7942\n",
      "epoch=180 ,train_loss=174.3725,valid_loss=126.3716\n",
      "epoch=181 ,train_loss=173.5075,valid_loss=125.9566\n",
      "epoch=182 ,train_loss=172.6528,valid_loss=125.5493\n",
      "epoch=183 ,train_loss=171.8084,valid_loss=125.1495\n",
      "epoch=184 ,train_loss=170.9741,valid_loss=124.7572\n",
      "epoch=185 ,train_loss=170.1496,valid_loss=124.3721\n",
      "epoch=186 ,train_loss=169.3350,valid_loss=123.9943\n",
      "epoch=187 ,train_loss=168.5303,valid_loss=123.6236\n",
      "epoch=188 ,train_loss=167.7352,valid_loss=123.2598\n",
      "epoch=189 ,train_loss=166.9495,valid_loss=122.9031\n",
      "epoch=190 ,train_loss=166.1732,valid_loss=122.5531\n",
      "epoch=191 ,train_loss=165.4063,valid_loss=122.2099\n",
      "epoch=192 ,train_loss=164.6485,valid_loss=121.8733\n",
      "epoch=193 ,train_loss=163.8997,valid_loss=121.5433\n",
      "epoch=194 ,train_loss=163.1600,valid_loss=121.2197\n",
      "epoch=195 ,train_loss=162.4290,valid_loss=120.9025\n",
      "epoch=196 ,train_loss=161.7068,valid_loss=120.5916\n",
      "epoch=197 ,train_loss=160.9933,valid_loss=120.2868\n",
      "epoch=198 ,train_loss=160.2882,valid_loss=119.9881\n",
      "epoch=199 ,train_loss=159.5916,valid_loss=119.6955\n",
      "epoch=200 ,train_loss=158.9034,valid_loss=119.4088\n",
      "epoch=201 ,train_loss=158.2235,valid_loss=119.1280\n",
      "epoch=202 ,train_loss=157.5517,valid_loss=118.8529\n",
      "epoch=203 ,train_loss=156.8878,valid_loss=118.5835\n",
      "epoch=204 ,train_loss=156.2319,valid_loss=118.3197\n",
      "epoch=205 ,train_loss=155.5838,valid_loss=118.0615\n",
      "epoch=206 ,train_loss=154.9435,valid_loss=117.8087\n",
      "epoch=207 ,train_loss=154.3110,valid_loss=117.5613\n",
      "epoch=208 ,train_loss=153.6860,valid_loss=117.3192\n",
      "epoch=209 ,train_loss=153.0684,valid_loss=117.0823\n",
      "epoch=210 ,train_loss=152.4582,valid_loss=116.8505\n",
      "epoch=211 ,train_loss=151.8554,valid_loss=116.6238\n",
      "epoch=212 ,train_loss=151.2597,valid_loss=116.4021\n",
      "epoch=213 ,train_loss=150.6712,valid_loss=116.1853\n",
      "epoch=214 ,train_loss=150.0897,valid_loss=115.9734\n",
      "epoch=215 ,train_loss=149.5152,valid_loss=115.7663\n",
      "epoch=216 ,train_loss=148.9476,valid_loss=115.5639\n",
      "epoch=217 ,train_loss=148.3868,valid_loss=115.3662\n",
      "epoch=218 ,train_loss=147.8326,valid_loss=115.1730\n",
      "epoch=219 ,train_loss=147.2851,valid_loss=114.9844\n",
      "epoch=220 ,train_loss=146.7442,valid_loss=114.8002\n",
      "epoch=221 ,train_loss=146.2098,valid_loss=114.6204\n",
      "epoch=222 ,train_loss=145.6818,valid_loss=114.4449\n",
      "epoch=223 ,train_loss=145.1601,valid_loss=114.2737\n",
      "epoch=224 ,train_loss=144.6447,valid_loss=114.1067\n",
      "epoch=225 ,train_loss=144.1355,valid_loss=113.9438\n",
      "epoch=226 ,train_loss=143.6324,valid_loss=113.7850\n",
      "epoch=227 ,train_loss=143.1353,valid_loss=113.6302\n",
      "epoch=228 ,train_loss=142.6441,valid_loss=113.4794\n",
      "epoch=229 ,train_loss=142.1588,valid_loss=113.3324\n",
      "epoch=230 ,train_loss=141.6794,valid_loss=113.1893\n",
      "epoch=231 ,train_loss=141.2057,valid_loss=113.0500\n",
      "epoch=232 ,train_loss=140.7377,valid_loss=112.9144\n",
      "epoch=233 ,train_loss=140.2752,valid_loss=112.7824\n",
      "epoch=234 ,train_loss=139.8184,valid_loss=112.6541\n",
      "epoch=235 ,train_loss=139.3670,valid_loss=112.5294\n",
      "epoch=236 ,train_loss=138.9210,valid_loss=112.4081\n",
      "epoch=237 ,train_loss=138.4804,valid_loss=112.2903\n",
      "epoch=238 ,train_loss=138.0450,valid_loss=112.1759\n",
      "epoch=239 ,train_loss=137.6149,valid_loss=112.0649\n",
      "epoch=240 ,train_loss=137.1899,valid_loss=111.9571\n",
      "epoch=241 ,train_loss=136.7700,valid_loss=111.8526\n",
      "epoch=242 ,train_loss=136.3552,valid_loss=111.7513\n",
      "epoch=243 ,train_loss=135.9454,valid_loss=111.6532\n",
      "epoch=244 ,train_loss=135.5405,valid_loss=111.5581\n",
      "epoch=245 ,train_loss=135.1405,valid_loss=111.4661\n",
      "epoch=246 ,train_loss=134.7452,valid_loss=111.3771\n",
      "epoch=247 ,train_loss=134.3547,valid_loss=111.2911\n",
      "epoch=248 ,train_loss=133.9688,valid_loss=111.2079\n",
      "epoch=249 ,train_loss=133.5876,valid_loss=111.1277\n",
      "epoch=250 ,train_loss=133.2110,valid_loss=111.0503\n",
      "epoch=251 ,train_loss=132.8389,valid_loss=110.9756\n",
      "epoch=252 ,train_loss=132.4712,valid_loss=110.9037\n",
      "epoch=253 ,train_loss=132.1080,valid_loss=110.8345\n",
      "epoch=254 ,train_loss=131.7491,valid_loss=110.7679\n",
      "epoch=255 ,train_loss=131.3946,valid_loss=110.7039\n",
      "epoch=256 ,train_loss=131.0444,valid_loss=110.6426\n",
      "epoch=257 ,train_loss=130.6983,valid_loss=110.5837\n",
      "epoch=258 ,train_loss=130.3563,valid_loss=110.5274\n",
      "epoch=259 ,train_loss=130.0185,valid_loss=110.4735\n",
      "epoch=260 ,train_loss=129.6847,valid_loss=110.4219\n",
      "epoch=261 ,train_loss=129.3548,valid_loss=110.3728\n",
      "epoch=262 ,train_loss=129.0290,valid_loss=110.3259\n",
      "epoch=263 ,train_loss=128.7072,valid_loss=110.2814\n",
      "epoch=264 ,train_loss=128.3892,valid_loss=110.2392\n",
      "epoch=265 ,train_loss=128.0749,valid_loss=110.1991\n",
      "epoch=266 ,train_loss=127.7645,valid_loss=110.1613\n",
      "epoch=267 ,train_loss=127.4578,valid_loss=110.1255\n",
      "epoch=268 ,train_loss=127.1548,valid_loss=110.0920\n",
      "epoch=269 ,train_loss=126.8554,valid_loss=110.0604\n",
      "epoch=270 ,train_loss=126.5596,valid_loss=110.0310\n",
      "epoch=271 ,train_loss=126.2673,valid_loss=110.0035\n",
      "epoch=272 ,train_loss=125.9786,valid_loss=109.9780\n",
      "epoch=273 ,train_loss=125.6933,valid_loss=109.9545\n",
      "epoch=274 ,train_loss=125.4115,valid_loss=109.9328\n",
      "epoch=275 ,train_loss=125.1331,valid_loss=109.9131\n",
      "epoch=276 ,train_loss=124.8580,valid_loss=109.8951\n",
      "epoch=277 ,train_loss=124.5863,valid_loss=109.8791\n",
      "epoch=278 ,train_loss=124.3178,valid_loss=109.8648\n",
      "epoch=279 ,train_loss=124.0525,valid_loss=109.8522\n",
      "epoch=280 ,train_loss=123.7904,valid_loss=109.8414\n",
      "epoch=281 ,train_loss=123.5315,valid_loss=109.8323\n",
      "epoch=282 ,train_loss=123.2757,valid_loss=109.8248\n",
      "epoch=283 ,train_loss=123.0229,valid_loss=109.8190\n",
      "epoch=284 ,train_loss=122.7732,valid_loss=109.8148\n",
      "epoch=285 ,train_loss=122.5264,valid_loss=109.8121\n",
      "epoch=286 ,train_loss=122.2827,valid_loss=109.8111\n",
      "epoch=287 ,train_loss=122.0419,valid_loss=109.8115\n",
      "epoch=288 ,train_loss=121.8039,valid_loss=109.8135\n",
      "epoch=289 ,train_loss=121.5689,valid_loss=109.8169\n",
      "epoch=290 ,train_loss=121.3366,valid_loss=109.8218\n",
      "epoch=291 ,train_loss=121.1071,valid_loss=109.8281\n",
      "epoch=292 ,train_loss=120.8804,valid_loss=109.8358\n",
      "epoch=293 ,train_loss=120.6565,valid_loss=109.8448\n",
      "epoch=294 ,train_loss=120.4352,valid_loss=109.8553\n",
      "epoch=295 ,train_loss=120.2166,valid_loss=109.8670\n",
      "epoch=296 ,train_loss=120.0007,valid_loss=109.8801\n",
      "epoch=297 ,train_loss=119.7873,valid_loss=109.8943\n",
      "epoch=298 ,train_loss=119.5765,valid_loss=109.9099\n",
      "epoch=299 ,train_loss=119.3683,valid_loss=109.9268\n",
      "epoch=300 ,train_loss=119.1625,valid_loss=109.9447\n",
      "epoch=301 ,train_loss=118.9592,valid_loss=109.9639\n",
      "epoch=302 ,train_loss=118.7583,valid_loss=109.9843\n",
      "epoch=303 ,train_loss=118.5599,valid_loss=110.0058\n",
      "epoch=304 ,train_loss=118.3638,valid_loss=110.0284\n",
      "epoch=305 ,train_loss=118.1702,valid_loss=110.0521\n",
      "epoch=306 ,train_loss=117.9789,valid_loss=110.0769\n",
      "epoch=307 ,train_loss=117.7899,valid_loss=110.1027\n",
      "epoch=308 ,train_loss=117.6031,valid_loss=110.1296\n",
      "epoch=309 ,train_loss=117.4185,valid_loss=110.1574\n",
      "epoch=310 ,train_loss=117.2362,valid_loss=110.1863\n",
      "epoch=311 ,train_loss=117.0561,valid_loss=110.2162\n",
      "epoch=312 ,train_loss=116.8781,valid_loss=110.2470\n",
      "epoch=313 ,train_loss=116.7023,valid_loss=110.2788\n",
      "epoch=314 ,train_loss=116.5287,valid_loss=110.3115\n",
      "epoch=315 ,train_loss=116.3571,valid_loss=110.3450\n",
      "epoch=316 ,train_loss=116.1876,valid_loss=110.3795\n",
      "epoch=317 ,train_loss=116.0201,valid_loss=110.4148\n",
      "epoch=318 ,train_loss=115.8547,valid_loss=110.4510\n",
      "epoch=319 ,train_loss=115.6913,valid_loss=110.4880\n",
      "epoch=320 ,train_loss=115.5297,valid_loss=110.5258\n",
      "epoch=321 ,train_loss=115.3702,valid_loss=110.5645\n",
      "epoch=322 ,train_loss=115.2126,valid_loss=110.6038\n",
      "epoch=323 ,train_loss=115.0568,valid_loss=110.6440\n",
      "epoch=324 ,train_loss=114.9030,valid_loss=110.6849\n",
      "epoch=325 ,train_loss=114.7510,valid_loss=110.7266\n",
      "epoch=326 ,train_loss=114.6009,valid_loss=110.7690\n",
      "epoch=327 ,train_loss=114.4525,valid_loss=110.8120\n",
      "epoch=328 ,train_loss=114.3059,valid_loss=110.8558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=329 ,train_loss=114.1612,valid_loss=110.9002\n",
      "epoch=330 ,train_loss=114.0181,valid_loss=110.9453\n",
      "epoch=331 ,train_loss=113.8768,valid_loss=110.9910\n",
      "epoch=332 ,train_loss=113.7371,valid_loss=111.0374\n",
      "epoch=333 ,train_loss=113.5992,valid_loss=111.0843\n",
      "epoch=334 ,train_loss=113.4629,valid_loss=111.1319\n",
      "epoch=335 ,train_loss=113.3283,valid_loss=111.1800\n",
      "epoch=336 ,train_loss=113.1952,valid_loss=111.2288\n",
      "epoch=337 ,train_loss=113.0639,valid_loss=111.2780\n",
      "epoch=338 ,train_loss=112.9341,valid_loss=111.3278\n",
      "epoch=339 ,train_loss=112.8058,valid_loss=111.3782\n",
      "epoch=340 ,train_loss=112.6791,valid_loss=111.4290\n",
      "epoch=341 ,train_loss=112.5540,valid_loss=111.4804\n",
      "epoch=342 ,train_loss=112.4303,valid_loss=111.5323\n",
      "epoch=343 ,train_loss=112.3081,valid_loss=111.5847\n",
      "epoch=344 ,train_loss=112.1874,valid_loss=111.6375\n",
      "epoch=345 ,train_loss=112.0682,valid_loss=111.6908\n",
      "epoch=346 ,train_loss=111.9503,valid_loss=111.7446\n",
      "epoch=347 ,train_loss=111.8340,valid_loss=111.7987\n",
      "epoch=348 ,train_loss=111.7190,valid_loss=111.8533\n",
      "epoch=349 ,train_loss=111.6054,valid_loss=111.9083\n",
      "epoch=350 ,train_loss=111.4931,valid_loss=111.9638\n",
      "epoch=351 ,train_loss=111.3823,valid_loss=112.0196\n",
      "epoch=352 ,train_loss=111.2728,valid_loss=112.0758\n",
      "epoch=353 ,train_loss=111.1646,valid_loss=112.1323\n",
      "epoch=354 ,train_loss=111.0577,valid_loss=112.1893\n",
      "epoch=355 ,train_loss=110.9520,valid_loss=112.2465\n",
      "epoch=356 ,train_loss=110.8477,valid_loss=112.3041\n",
      "epoch=357 ,train_loss=110.7447,valid_loss=112.3621\n",
      "epoch=358 ,train_loss=110.6428,valid_loss=112.4203\n",
      "epoch=359 ,train_loss=110.5422,valid_loss=112.4790\n",
      "epoch=360 ,train_loss=110.4428,valid_loss=112.5378\n",
      "epoch=361 ,train_loss=110.3447,valid_loss=112.5969\n",
      "epoch=362 ,train_loss=110.2477,valid_loss=112.6564\n",
      "epoch=363 ,train_loss=110.1519,valid_loss=112.7162\n",
      "epoch=364 ,train_loss=110.0572,valid_loss=112.7762\n",
      "epoch=365 ,train_loss=109.9637,valid_loss=112.8364\n",
      "epoch=366 ,train_loss=109.8713,valid_loss=112.8970\n",
      "epoch=367 ,train_loss=109.7801,valid_loss=112.9577\n",
      "epoch=368 ,train_loss=109.6899,valid_loss=113.0187\n",
      "epoch=369 ,train_loss=109.6009,valid_loss=113.0798\n",
      "epoch=370 ,train_loss=109.5129,valid_loss=113.1413\n",
      "epoch=371 ,train_loss=109.4260,valid_loss=113.2029\n",
      "epoch=372 ,train_loss=109.3401,valid_loss=113.2648\n",
      "epoch=373 ,train_loss=109.2553,valid_loss=113.3268\n",
      "epoch=374 ,train_loss=109.1715,valid_loss=113.3890\n",
      "epoch=375 ,train_loss=109.0887,valid_loss=113.4513\n",
      "epoch=376 ,train_loss=109.0069,valid_loss=113.5139\n",
      "epoch=377 ,train_loss=108.9262,valid_loss=113.5766\n",
      "epoch=378 ,train_loss=108.8464,valid_loss=113.6395\n",
      "epoch=379 ,train_loss=108.7675,valid_loss=113.7025\n",
      "epoch=380 ,train_loss=108.6897,valid_loss=113.7656\n",
      "epoch=381 ,train_loss=108.6127,valid_loss=113.8289\n",
      "epoch=382 ,train_loss=108.5367,valid_loss=113.8923\n",
      "epoch=383 ,train_loss=108.4616,valid_loss=113.9559\n",
      "epoch=384 ,train_loss=108.3875,valid_loss=114.0195\n",
      "epoch=385 ,train_loss=108.3141,valid_loss=114.0834\n",
      "epoch=386 ,train_loss=108.2417,valid_loss=114.1472\n",
      "epoch=387 ,train_loss=108.1702,valid_loss=114.2112\n",
      "epoch=388 ,train_loss=108.0996,valid_loss=114.2753\n",
      "epoch=389 ,train_loss=108.0298,valid_loss=114.3394\n",
      "epoch=390 ,train_loss=107.9609,valid_loss=114.4037\n",
      "epoch=391 ,train_loss=107.8928,valid_loss=114.4680\n",
      "epoch=392 ,train_loss=107.8255,valid_loss=114.5323\n",
      "epoch=393 ,train_loss=107.7590,valid_loss=114.5968\n",
      "epoch=394 ,train_loss=107.6934,valid_loss=114.6613\n",
      "epoch=395 ,train_loss=107.6285,valid_loss=114.7259\n",
      "epoch=396 ,train_loss=107.5645,valid_loss=114.7904\n",
      "epoch=397 ,train_loss=107.5012,valid_loss=114.8551\n",
      "epoch=398 ,train_loss=107.4387,valid_loss=114.9197\n",
      "epoch=399 ,train_loss=107.3769,valid_loss=114.9845\n",
      "epoch=400 ,train_loss=107.3159,valid_loss=115.0492\n",
      "epoch=401 ,train_loss=107.2556,valid_loss=115.1140\n",
      "epoch=402 ,train_loss=107.1961,valid_loss=115.1787\n",
      "epoch=403 ,train_loss=107.1373,valid_loss=115.2436\n",
      "epoch=404 ,train_loss=107.0792,valid_loss=115.3084\n",
      "epoch=405 ,train_loss=107.0218,valid_loss=115.3732\n",
      "epoch=406 ,train_loss=106.9651,valid_loss=115.4380\n",
      "epoch=407 ,train_loss=106.9091,valid_loss=115.5028\n",
      "epoch=408 ,train_loss=106.8538,valid_loss=115.5676\n",
      "epoch=409 ,train_loss=106.7992,valid_loss=115.6324\n",
      "epoch=410 ,train_loss=106.7452,valid_loss=115.6972\n",
      "epoch=411 ,train_loss=106.6919,valid_loss=115.7619\n",
      "epoch=412 ,train_loss=106.6392,valid_loss=115.8267\n",
      "epoch=413 ,train_loss=106.5872,valid_loss=115.8914\n",
      "epoch=414 ,train_loss=106.5358,valid_loss=115.9561\n",
      "epoch=415 ,train_loss=106.4851,valid_loss=116.0207\n",
      "epoch=416 ,train_loss=106.4349,valid_loss=116.0853\n",
      "epoch=417 ,train_loss=106.3854,valid_loss=116.1498\n",
      "epoch=418 ,train_loss=106.3365,valid_loss=116.2143\n",
      "epoch=419 ,train_loss=106.2881,valid_loss=116.2788\n",
      "epoch=420 ,train_loss=106.2404,valid_loss=116.3432\n",
      "epoch=421 ,train_loss=106.1932,valid_loss=116.4075\n",
      "epoch=422 ,train_loss=106.1467,valid_loss=116.4718\n",
      "epoch=423 ,train_loss=106.1006,valid_loss=116.5360\n",
      "epoch=424 ,train_loss=106.0552,valid_loss=116.6002\n",
      "epoch=425 ,train_loss=106.0103,valid_loss=116.6643\n",
      "epoch=426 ,train_loss=105.9660,valid_loss=116.7283\n",
      "epoch=427 ,train_loss=105.9221,valid_loss=116.7923\n",
      "epoch=428 ,train_loss=105.8789,valid_loss=116.8562\n",
      "epoch=429 ,train_loss=105.8361,valid_loss=116.9200\n",
      "epoch=430 ,train_loss=105.7939,valid_loss=116.9837\n",
      "epoch=431 ,train_loss=105.7522,valid_loss=117.0473\n",
      "epoch=432 ,train_loss=105.7110,valid_loss=117.1108\n",
      "epoch=433 ,train_loss=105.6703,valid_loss=117.1743\n",
      "epoch=434 ,train_loss=105.6301,valid_loss=117.2376\n",
      "epoch=435 ,train_loss=105.5904,valid_loss=117.3009\n",
      "epoch=436 ,train_loss=105.5512,valid_loss=117.3640\n",
      "epoch=437 ,train_loss=105.5125,valid_loss=117.4271\n",
      "epoch=438 ,train_loss=105.4742,valid_loss=117.4900\n",
      "epoch=439 ,train_loss=105.4365,valid_loss=117.5528\n",
      "epoch=440 ,train_loss=105.3992,valid_loss=117.6155\n",
      "epoch=441 ,train_loss=105.3623,valid_loss=117.6782\n",
      "epoch=442 ,train_loss=105.3259,valid_loss=117.7407\n",
      "epoch=443 ,train_loss=105.2899,valid_loss=117.8031\n",
      "epoch=444 ,train_loss=105.2544,valid_loss=117.8654\n",
      "epoch=445 ,train_loss=105.2193,valid_loss=117.9275\n",
      "epoch=446 ,train_loss=105.1847,valid_loss=117.9896\n",
      "epoch=447 ,train_loss=105.1505,valid_loss=118.0515\n",
      "epoch=448 ,train_loss=105.1167,valid_loss=118.1133\n",
      "epoch=449 ,train_loss=105.0833,valid_loss=118.1750\n",
      "epoch=450 ,train_loss=105.0504,valid_loss=118.2365\n",
      "epoch=451 ,train_loss=105.0178,valid_loss=118.2979\n",
      "epoch=452 ,train_loss=104.9856,valid_loss=118.3593\n",
      "epoch=453 ,train_loss=104.9538,valid_loss=118.4203\n",
      "epoch=454 ,train_loss=104.9225,valid_loss=118.4813\n",
      "epoch=455 ,train_loss=104.8915,valid_loss=118.5422\n",
      "epoch=456 ,train_loss=104.8609,valid_loss=118.6029\n",
      "epoch=457 ,train_loss=104.8307,valid_loss=118.6635\n",
      "epoch=458 ,train_loss=104.8008,valid_loss=118.7239\n",
      "epoch=459 ,train_loss=104.7714,valid_loss=118.7842\n",
      "epoch=460 ,train_loss=104.7423,valid_loss=118.8444\n",
      "epoch=461 ,train_loss=104.7135,valid_loss=118.9043\n",
      "epoch=462 ,train_loss=104.6851,valid_loss=118.9641\n",
      "epoch=463 ,train_loss=104.6571,valid_loss=119.0239\n",
      "epoch=464 ,train_loss=104.6294,valid_loss=119.0834\n",
      "epoch=465 ,train_loss=104.6021,valid_loss=119.1428\n",
      "epoch=466 ,train_loss=104.5751,valid_loss=119.2021\n",
      "epoch=467 ,train_loss=104.5484,valid_loss=119.2612\n",
      "epoch=468 ,train_loss=104.5220,valid_loss=119.3201\n",
      "epoch=469 ,train_loss=104.4960,valid_loss=119.3789\n",
      "epoch=470 ,train_loss=104.4703,valid_loss=119.4376\n",
      "epoch=471 ,train_loss=104.4449,valid_loss=119.4960\n",
      "epoch=472 ,train_loss=104.4198,valid_loss=119.5543\n",
      "epoch=473 ,train_loss=104.3951,valid_loss=119.6125\n",
      "epoch=474 ,train_loss=104.3706,valid_loss=119.6705\n",
      "epoch=475 ,train_loss=104.3465,valid_loss=119.7284\n",
      "epoch=476 ,train_loss=104.3226,valid_loss=119.7861\n",
      "epoch=477 ,train_loss=104.2991,valid_loss=119.8436\n",
      "epoch=478 ,train_loss=104.2758,valid_loss=119.9010\n",
      "epoch=479 ,train_loss=104.2529,valid_loss=119.9582\n",
      "epoch=480 ,train_loss=104.2302,valid_loss=120.0152\n",
      "epoch=481 ,train_loss=104.2078,valid_loss=120.0720\n",
      "epoch=482 ,train_loss=104.1857,valid_loss=120.1287\n",
      "epoch=483 ,train_loss=104.1639,valid_loss=120.1853\n",
      "epoch=484 ,train_loss=104.1424,valid_loss=120.2416\n",
      "epoch=485 ,train_loss=104.1211,valid_loss=120.2978\n",
      "epoch=486 ,train_loss=104.1000,valid_loss=120.3538\n",
      "epoch=487 ,train_loss=104.0793,valid_loss=120.4096\n",
      "epoch=488 ,train_loss=104.0588,valid_loss=120.4652\n",
      "epoch=489 ,train_loss=104.0386,valid_loss=120.5207\n",
      "epoch=490 ,train_loss=104.0186,valid_loss=120.5760\n",
      "epoch=491 ,train_loss=103.9989,valid_loss=120.6312\n",
      "epoch=492 ,train_loss=103.9794,valid_loss=120.6861\n",
      "epoch=493 ,train_loss=103.9602,valid_loss=120.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=494 ,train_loss=103.9412,valid_loss=120.7955\n",
      "epoch=495 ,train_loss=103.9224,valid_loss=120.8500\n",
      "epoch=496 ,train_loss=103.9039,valid_loss=120.9042\n",
      "epoch=497 ,train_loss=103.8856,valid_loss=120.9584\n",
      "epoch=498 ,train_loss=103.8675,valid_loss=121.0123\n",
      "epoch=499 ,train_loss=103.8497,valid_loss=121.0661\n",
      "epoch=500 ,train_loss=103.8321,valid_loss=121.1196\n"
     ]
    }
   ],
   "source": [
    "loss_list_train = []\n",
    "loss_list_valid = []\n",
    "total_step = int (train_num/batch_size)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    for step in range(total_step):\n",
    "        xs = x_train[step*batch_size:(step+1)*batch_size,:]\n",
    "        ys = y_train[step*batch_size:(step+1)*batch_size]\n",
    "        \n",
    "        grads = grad(xs,ys,W,B)\n",
    "        optimizer.apply_gradients(zip(grads,[W,B]))\n",
    "        \n",
    "    loss_train = loss(x_train, y_train,W ,B).numpy()\n",
    "    loss_valid = loss(x_valid, y_valid,W ,B).numpy()\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "    print(\"epoch={:3d} ,train_loss={:.4f},valid_loss={:.4f}\".format(epoch+1,loss_train,loss_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss:113.5717\n",
      "<tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
      "array([[ 0.29776895],\n",
      "       [ 0.3685904 ],\n",
      "       [-0.66927135],\n",
      "       [ 0.67803794],\n",
      "       [-1.8162059 ],\n",
      "       [ 1.4693649 ],\n",
      "       [-0.22928289],\n",
      "       [-1.2676358 ],\n",
      "       [ 0.58518386],\n",
      "       [-0.76447606],\n",
      "       [-2.5849106 ],\n",
      "       [-0.71795756]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([24.220371], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_loss:{:.4f}\".format(loss(x_test, y_test, W, B).numpy()))\n",
    "#print(\"W:{:.4f}\".format(W.numpy()))\n",
    "#print(\"B:{:.4f}\".format(B))\n",
    "print(W)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
